from utils.support import get_logger, pkl_dump, jsn_dump

import os
from pathlib import Path
import pandas as pd
import cv2
import numpy as np


def gen_dataset_df(data_path_):
    """Collect table with full paths to image files, their sizes in bytes
    and images themselves as numpy.arrays.

    Args:
        data_path_ (str): path to the folder with the images.

    Returns:
        dataset_df (pandas.DataFrame): DataFrame with 3 columns: img_path, size, img.
    """
    dataset_df = pd.DataFrame()

    for dir_name, _, file_names in os.walk(data_path_):
        for filename in file_names:
            img_path = Path(os.path.join(dir_name, filename))
            size_ = img_path.stat().st_size
            dataset_df = dataset_df.append({
                "img_path": img_path,
                "size": size_,
                "img": cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE),
            }, ignore_index=True)

    dataset_df["size"] = dataset_df["size"].astype(int)
    dataset_df = dataset_df[~dataset_df["img"].isnull()]

    return dataset_df


def gen_identity_df(original_df, cew_df):
    """Returns mapping for images between original and CEW datasets.

    Args:
        original_df (pandas.DataFrame): dataset_df generated by gen_dataset_df function
            from the original dataset.
        cew_df (pandas.DataFrame): dataset_df generated by gen_dataset_df function
            from the CEW dataset.

    Returns:
        df (pandas.DataFrame): dataframe with 2 columns:
            cew_img - contains a path to an image from CEW dataset;
            original_img - contains a path to an image from the original dataset
                if it exists there, otherwise None.
    """

    df = pd.DataFrame()
    for size in cew_df["size"].unique():
        ext_df = cew_df[cew_df["size"] == size]
        int_df = original_df[original_df["size"] == size]

        for _, ext_row in ext_df.iterrows():
            pair = None
            for _, int_row in int_df.iterrows():
                if (ext_row["img"] == int_row["img"]).all():
                    pair = int_row["img_path"]
                    break

            df = df.append({
                "cew_img": ext_row["img_path"],
                "original_img": pair
            }, ignore_index=True)
    return df


def main(config, logger):
    np.random.seed(config["seed"])
    pth = Path(config["output"]) / "crossval_split"
    os.makedirs(pth, exist_ok=True)
    jsn_dump(config, pth / "config.jsn")
    # CHECK IDENTITY
    cew = gen_dataset_df(config["cew_path"])
    logger.info("CEW dataset_df generated.")

    original = gen_dataset_df(config["original_path"])
    logger.info("Original dataset_df generated.")

    identity_df = gen_identity_df(original, cew)
    logger.info("Identity_df generated.")

    # Collect labels into identity_df
    identity_df["label"] = identity_df["cew_img"].apply(lambda x: x.parent.name).map({
        "openLeftEyes": 1,
        "openRightEyes": 1,
        "closedLeftEyes": 0,
        "closedRightEyes": 0,
    })
    assert identity_df["label"].isnull().sum() == 0, "Identity_df has NaN in labels."

    # saving identity_df
    pkl_dump(identity_df, pth / "identity_df.pkl")

    # If the number of original images with a pair from CEW dataset
    # equal to the number of original images, then datasets are identical
    if not (~identity_df["original_img"].isnull()).sum() == len(original):
        logger.info("Datasets are NOT identical!")
    else:
        logger.info("Datasets are identical!")

        # CROSS_VALIDATION SPLIT

        # Hidden Images
        #   Take N images, which exist in CEW dataset and do not exist in the provided dataset.
        #   N - is the difference between the number of images in CEW dataset and the provided dataset.
        hidden_images = np.random.choice(
            a=identity_df[~identity_df["original_img"].isnull()]["cew_img"].values,
            size=identity_df["original_img"].isnull().sum(),
            replace=False
        )
        crossval_dct = {
            "hidden": identity_df[identity_df["cew_img"].isin(hidden_images)]
        }
        identity_df = identity_df[~identity_df["cew_img"].isin(hidden_images)]

        # Fold 1:
        # train - images, which do not exist in the original dataset + random images
        all_images = identity_df["cew_img"].values
        train_size = int(len(all_images) * ((config["folds"] - 1) / config["folds"]))
        valid_size = int(len(all_images) * (1 / config["folds"]))

        train_images = identity_df[identity_df["cew_img"].isnull()]["cew_img"].values
        train_images = np.append(train_images, np.random.choice(np.setdiff1d(all_images, train_images),
                                                                train_size - len(train_images), replace=False))
        valid_images = np.setdiff1d(all_images, train_images)

        crossval_dct[1] = {
            "train": identity_df[identity_df["cew_img"].isin(train_images)],
            "valid": identity_df[identity_df["cew_img"].isin(valid_images)],
        }

        # Folds 2-5
        all_valid_images = valid_images
        for fold in range(2, 6):
            valid_images = np.random.choice(np.setdiff1d(all_images, all_valid_images), valid_size, replace=False)
            train_images = np.setdiff1d(all_images, valid_images)
            crossval_dct[fold] = {
                "train": identity_df[identity_df["cew_img"].isin(train_images)],
                "valid": identity_df[identity_df["cew_img"].isin(valid_images)],
            }
            all_valid_images = np.append(all_valid_images, valid_images)

        # saving crossval_dct
        pkl_dump(crossval_dct, pth / "crossval_dct.pkl")


if __name__ == "__main__":
    cfg = {
        "cew_path": "../data/dataset_B_Eye_Images/",
        "original_path": "../data/EyesDataset",
        "output": "../output",
        "folds": 5,
        "seed": 0
    }

    main(cfg, get_logger("datasets_identity_check"))
