{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils.support import pkl_load\n",
    "from train.run import MyDataset\n",
    "from train.versions.augmentation import get_augmentation\n",
    "from train.versions.model import get_model\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = pkl_load(\"../output/models/v-2/fold-1/progress.pkl\")\n",
    "p3 = pkl_load(\"../output/models/v-3/fold-1/progress.pkl\")\n",
    "p4 = pkl_load(\"../output/models/v-4/fold-1/progress.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_loss</th>\n",
       "      <th>raw_accuracy</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.064512</td>\n",
       "      <td>0.974375</td>\n",
       "      <td>0.042238</td>\n",
       "      <td>0.984688</td>\n",
       "      <td>0.089217</td>\n",
       "      <td>0.9675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    raw_loss  raw_accuracy  train_loss  train_accuracy  valid_loss  \\\n",
       "29  0.064512      0.974375    0.042238        0.984688    0.089217   \n",
       "\n",
       "    valid_accuracy  \n",
       "29          0.9675  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p4[p4[\"valid_loss\"] == p4[\"valid_loss\"].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_loss</th>\n",
       "      <th>raw_accuracy</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.692623</td>\n",
       "      <td>0.486875</td>\n",
       "      <td>0.687616</td>\n",
       "      <td>0.486875</td>\n",
       "      <td>0.686718</td>\n",
       "      <td>0.50125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.649093</td>\n",
       "      <td>0.730313</td>\n",
       "      <td>0.639730</td>\n",
       "      <td>0.765312</td>\n",
       "      <td>0.643467</td>\n",
       "      <td>0.74500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.524029</td>\n",
       "      <td>0.778125</td>\n",
       "      <td>0.522804</td>\n",
       "      <td>0.814375</td>\n",
       "      <td>0.529856</td>\n",
       "      <td>0.79875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.337692</td>\n",
       "      <td>0.869687</td>\n",
       "      <td>0.358032</td>\n",
       "      <td>0.874375</td>\n",
       "      <td>0.376296</td>\n",
       "      <td>0.85500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.253257</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.251946</td>\n",
       "      <td>0.889687</td>\n",
       "      <td>0.300666</td>\n",
       "      <td>0.86250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.238000</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.189908</td>\n",
       "      <td>0.923750</td>\n",
       "      <td>0.230385</td>\n",
       "      <td>0.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.197534</td>\n",
       "      <td>0.918750</td>\n",
       "      <td>0.165805</td>\n",
       "      <td>0.938438</td>\n",
       "      <td>0.185338</td>\n",
       "      <td>0.92625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.160756</td>\n",
       "      <td>0.939688</td>\n",
       "      <td>0.183948</td>\n",
       "      <td>0.924687</td>\n",
       "      <td>0.211461</td>\n",
       "      <td>0.92125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.146434</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.139304</td>\n",
       "      <td>0.941562</td>\n",
       "      <td>0.152639</td>\n",
       "      <td>0.94750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.135829</td>\n",
       "      <td>0.952500</td>\n",
       "      <td>0.127833</td>\n",
       "      <td>0.949063</td>\n",
       "      <td>0.144961</td>\n",
       "      <td>0.94125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.130845</td>\n",
       "      <td>0.950313</td>\n",
       "      <td>0.110474</td>\n",
       "      <td>0.957500</td>\n",
       "      <td>0.145247</td>\n",
       "      <td>0.94750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.134996</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.133448</td>\n",
       "      <td>0.947812</td>\n",
       "      <td>0.175283</td>\n",
       "      <td>0.92375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.122064</td>\n",
       "      <td>0.950937</td>\n",
       "      <td>0.094966</td>\n",
       "      <td>0.964063</td>\n",
       "      <td>0.128372</td>\n",
       "      <td>0.94125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.122281</td>\n",
       "      <td>0.951562</td>\n",
       "      <td>0.095041</td>\n",
       "      <td>0.964375</td>\n",
       "      <td>0.128668</td>\n",
       "      <td>0.95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.114718</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.091324</td>\n",
       "      <td>0.960313</td>\n",
       "      <td>0.110588</td>\n",
       "      <td>0.95500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.103703</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.089090</td>\n",
       "      <td>0.969063</td>\n",
       "      <td>0.121293</td>\n",
       "      <td>0.94875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.099897</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.078637</td>\n",
       "      <td>0.969688</td>\n",
       "      <td>0.112897</td>\n",
       "      <td>0.96125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.084601</td>\n",
       "      <td>0.967187</td>\n",
       "      <td>0.073778</td>\n",
       "      <td>0.972812</td>\n",
       "      <td>0.106921</td>\n",
       "      <td>0.96375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.093530</td>\n",
       "      <td>0.965625</td>\n",
       "      <td>0.072887</td>\n",
       "      <td>0.971250</td>\n",
       "      <td>0.095091</td>\n",
       "      <td>0.97000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.088419</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>0.089105</td>\n",
       "      <td>0.965938</td>\n",
       "      <td>0.126971</td>\n",
       "      <td>0.95250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.098587</td>\n",
       "      <td>0.962812</td>\n",
       "      <td>0.075765</td>\n",
       "      <td>0.969375</td>\n",
       "      <td>0.106596</td>\n",
       "      <td>0.96000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.087935</td>\n",
       "      <td>0.965313</td>\n",
       "      <td>0.066636</td>\n",
       "      <td>0.976875</td>\n",
       "      <td>0.103552</td>\n",
       "      <td>0.96125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.097287</td>\n",
       "      <td>0.961250</td>\n",
       "      <td>0.066769</td>\n",
       "      <td>0.974688</td>\n",
       "      <td>0.122701</td>\n",
       "      <td>0.94750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.086598</td>\n",
       "      <td>0.965938</td>\n",
       "      <td>0.059359</td>\n",
       "      <td>0.977812</td>\n",
       "      <td>0.102634</td>\n",
       "      <td>0.95625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.083748</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>0.093557</td>\n",
       "      <td>0.964375</td>\n",
       "      <td>0.125723</td>\n",
       "      <td>0.94875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.081632</td>\n",
       "      <td>0.969375</td>\n",
       "      <td>0.066629</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.113911</td>\n",
       "      <td>0.95375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.073621</td>\n",
       "      <td>0.972812</td>\n",
       "      <td>0.057384</td>\n",
       "      <td>0.977187</td>\n",
       "      <td>0.113360</td>\n",
       "      <td>0.95875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.074638</td>\n",
       "      <td>0.973125</td>\n",
       "      <td>0.055004</td>\n",
       "      <td>0.980313</td>\n",
       "      <td>0.111508</td>\n",
       "      <td>0.96125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.066332</td>\n",
       "      <td>0.973437</td>\n",
       "      <td>0.047363</td>\n",
       "      <td>0.981250</td>\n",
       "      <td>0.096776</td>\n",
       "      <td>0.96875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.064512</td>\n",
       "      <td>0.974375</td>\n",
       "      <td>0.042238</td>\n",
       "      <td>0.984688</td>\n",
       "      <td>0.089217</td>\n",
       "      <td>0.96750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.061607</td>\n",
       "      <td>0.978125</td>\n",
       "      <td>0.058001</td>\n",
       "      <td>0.976250</td>\n",
       "      <td>0.122874</td>\n",
       "      <td>0.95625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.073316</td>\n",
       "      <td>0.970938</td>\n",
       "      <td>0.109526</td>\n",
       "      <td>0.954688</td>\n",
       "      <td>0.169287</td>\n",
       "      <td>0.93750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.080343</td>\n",
       "      <td>0.969375</td>\n",
       "      <td>0.077241</td>\n",
       "      <td>0.966875</td>\n",
       "      <td>0.147217</td>\n",
       "      <td>0.94750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.074257</td>\n",
       "      <td>0.970313</td>\n",
       "      <td>0.046718</td>\n",
       "      <td>0.982500</td>\n",
       "      <td>0.106520</td>\n",
       "      <td>0.95500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.062928</td>\n",
       "      <td>0.975313</td>\n",
       "      <td>0.044251</td>\n",
       "      <td>0.982500</td>\n",
       "      <td>0.106334</td>\n",
       "      <td>0.96250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.056055</td>\n",
       "      <td>0.978750</td>\n",
       "      <td>0.036163</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.101971</td>\n",
       "      <td>0.96625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.055703</td>\n",
       "      <td>0.979688</td>\n",
       "      <td>0.033668</td>\n",
       "      <td>0.987812</td>\n",
       "      <td>0.100486</td>\n",
       "      <td>0.96750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.051263</td>\n",
       "      <td>0.980938</td>\n",
       "      <td>0.037277</td>\n",
       "      <td>0.986563</td>\n",
       "      <td>0.107846</td>\n",
       "      <td>0.96000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.051348</td>\n",
       "      <td>0.977500</td>\n",
       "      <td>0.051717</td>\n",
       "      <td>0.980625</td>\n",
       "      <td>0.135191</td>\n",
       "      <td>0.96125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.072238</td>\n",
       "      <td>0.973437</td>\n",
       "      <td>0.121121</td>\n",
       "      <td>0.954063</td>\n",
       "      <td>0.210048</td>\n",
       "      <td>0.92625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.086414</td>\n",
       "      <td>0.966875</td>\n",
       "      <td>0.116134</td>\n",
       "      <td>0.951875</td>\n",
       "      <td>0.194527</td>\n",
       "      <td>0.93875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.075594</td>\n",
       "      <td>0.967812</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.985313</td>\n",
       "      <td>0.110166</td>\n",
       "      <td>0.96000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.075621</td>\n",
       "      <td>0.972500</td>\n",
       "      <td>0.041839</td>\n",
       "      <td>0.982812</td>\n",
       "      <td>0.116236</td>\n",
       "      <td>0.95875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.061284</td>\n",
       "      <td>0.977187</td>\n",
       "      <td>0.036274</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.111483</td>\n",
       "      <td>0.95500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.053727</td>\n",
       "      <td>0.979062</td>\n",
       "      <td>0.033277</td>\n",
       "      <td>0.989688</td>\n",
       "      <td>0.106348</td>\n",
       "      <td>0.96125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.052583</td>\n",
       "      <td>0.980938</td>\n",
       "      <td>0.031793</td>\n",
       "      <td>0.989688</td>\n",
       "      <td>0.098363</td>\n",
       "      <td>0.96250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.044015</td>\n",
       "      <td>0.983750</td>\n",
       "      <td>0.030606</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>0.093426</td>\n",
       "      <td>0.97000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.045216</td>\n",
       "      <td>0.984062</td>\n",
       "      <td>0.032584</td>\n",
       "      <td>0.988750</td>\n",
       "      <td>0.096896</td>\n",
       "      <td>0.96375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.049731</td>\n",
       "      <td>0.981563</td>\n",
       "      <td>0.029615</td>\n",
       "      <td>0.990938</td>\n",
       "      <td>0.093449</td>\n",
       "      <td>0.96500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.049727</td>\n",
       "      <td>0.983125</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.090316</td>\n",
       "      <td>0.96625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.044027</td>\n",
       "      <td>0.985313</td>\n",
       "      <td>0.026720</td>\n",
       "      <td>0.991563</td>\n",
       "      <td>0.091912</td>\n",
       "      <td>0.96750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.045355</td>\n",
       "      <td>0.983125</td>\n",
       "      <td>0.026364</td>\n",
       "      <td>0.992812</td>\n",
       "      <td>0.092413</td>\n",
       "      <td>0.96875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.987812</td>\n",
       "      <td>0.025125</td>\n",
       "      <td>0.993437</td>\n",
       "      <td>0.093487</td>\n",
       "      <td>0.97000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.040385</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>0.024441</td>\n",
       "      <td>0.993437</td>\n",
       "      <td>0.094739</td>\n",
       "      <td>0.97000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.040251</td>\n",
       "      <td>0.985938</td>\n",
       "      <td>0.023090</td>\n",
       "      <td>0.994062</td>\n",
       "      <td>0.093447</td>\n",
       "      <td>0.96625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.040521</td>\n",
       "      <td>0.986875</td>\n",
       "      <td>0.023038</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.094464</td>\n",
       "      <td>0.96500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.036976</td>\n",
       "      <td>0.987812</td>\n",
       "      <td>0.022138</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.096676</td>\n",
       "      <td>0.96500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.034681</td>\n",
       "      <td>0.988750</td>\n",
       "      <td>0.021839</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>0.099407</td>\n",
       "      <td>0.96250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.040629</td>\n",
       "      <td>0.986563</td>\n",
       "      <td>0.021620</td>\n",
       "      <td>0.994687</td>\n",
       "      <td>0.100675</td>\n",
       "      <td>0.96375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.035330</td>\n",
       "      <td>0.989062</td>\n",
       "      <td>0.020808</td>\n",
       "      <td>0.994687</td>\n",
       "      <td>0.101289</td>\n",
       "      <td>0.96500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    raw_loss  raw_accuracy  train_loss  train_accuracy  valid_loss  \\\n",
       "0   0.692623      0.486875    0.687616        0.486875    0.686718   \n",
       "1   0.649093      0.730313    0.639730        0.765312    0.643467   \n",
       "2   0.524029      0.778125    0.522804        0.814375    0.529856   \n",
       "3   0.337692      0.869687    0.358032        0.874375    0.376296   \n",
       "4   0.253257      0.890625    0.251946        0.889687    0.300666   \n",
       "5   0.238000      0.901563    0.189908        0.923750    0.230385   \n",
       "6   0.197534      0.918750    0.165805        0.938438    0.185338   \n",
       "7   0.160756      0.939688    0.183948        0.924687    0.211461   \n",
       "8   0.146434      0.942500    0.139304        0.941562    0.152639   \n",
       "9   0.135829      0.952500    0.127833        0.949063    0.144961   \n",
       "10  0.130845      0.950313    0.110474        0.957500    0.145247   \n",
       "11  0.134996      0.950000    0.133448        0.947812    0.175283   \n",
       "12  0.122064      0.950937    0.094966        0.964063    0.128372   \n",
       "13  0.122281      0.951562    0.095041        0.964375    0.128668   \n",
       "14  0.114718      0.955000    0.091324        0.960313    0.110588   \n",
       "15  0.103703      0.960000    0.089090        0.969063    0.121293   \n",
       "16  0.099897      0.962500    0.078637        0.969688    0.112897   \n",
       "17  0.084601      0.967187    0.073778        0.972812    0.106921   \n",
       "18  0.093530      0.965625    0.072887        0.971250    0.095091   \n",
       "19  0.088419      0.967500    0.089105        0.965938    0.126971   \n",
       "20  0.098587      0.962812    0.075765        0.969375    0.106596   \n",
       "21  0.087935      0.965313    0.066636        0.976875    0.103552   \n",
       "22  0.097287      0.961250    0.066769        0.974688    0.122701   \n",
       "23  0.086598      0.965938    0.059359        0.977812    0.102634   \n",
       "24  0.083748      0.967500    0.093557        0.964375    0.125723   \n",
       "25  0.081632      0.969375    0.066629        0.975000    0.113911   \n",
       "26  0.073621      0.972812    0.057384        0.977187    0.113360   \n",
       "27  0.074638      0.973125    0.055004        0.980313    0.111508   \n",
       "28  0.066332      0.973437    0.047363        0.981250    0.096776   \n",
       "29  0.064512      0.974375    0.042238        0.984688    0.089217   \n",
       "30  0.061607      0.978125    0.058001        0.976250    0.122874   \n",
       "31  0.073316      0.970938    0.109526        0.954688    0.169287   \n",
       "32  0.080343      0.969375    0.077241        0.966875    0.147217   \n",
       "33  0.074257      0.970313    0.046718        0.982500    0.106520   \n",
       "34  0.062928      0.975313    0.044251        0.982500    0.106334   \n",
       "35  0.056055      0.978750    0.036163        0.987500    0.101971   \n",
       "36  0.055703      0.979688    0.033668        0.987812    0.100486   \n",
       "37  0.051263      0.980938    0.037277        0.986563    0.107846   \n",
       "38  0.051348      0.977500    0.051717        0.980625    0.135191   \n",
       "39  0.072238      0.973437    0.121121        0.954063    0.210048   \n",
       "40  0.086414      0.966875    0.116134        0.951875    0.194527   \n",
       "41  0.075594      0.967812    0.042017        0.985313    0.110166   \n",
       "42  0.075621      0.972500    0.041839        0.982812    0.116236   \n",
       "43  0.061284      0.977187    0.036274        0.985000    0.111483   \n",
       "44  0.053727      0.979062    0.033277        0.989688    0.106348   \n",
       "45  0.052583      0.980938    0.031793        0.989688    0.098363   \n",
       "46  0.044015      0.983750    0.030606        0.990625    0.093426   \n",
       "47  0.045216      0.984062    0.032584        0.988750    0.096896   \n",
       "48  0.049731      0.981563    0.029615        0.990938    0.093449   \n",
       "49  0.049727      0.983125    0.027100        0.992188    0.090316   \n",
       "50  0.044027      0.985313    0.026720        0.991563    0.091912   \n",
       "51  0.045355      0.983125    0.026364        0.992812    0.092413   \n",
       "52  0.037760      0.987812    0.025125        0.993437    0.093487   \n",
       "53  0.040385      0.985625    0.024441        0.993437    0.094739   \n",
       "54  0.040251      0.985938    0.023090        0.994062    0.093447   \n",
       "55  0.040521      0.986875    0.023038        0.995000    0.094464   \n",
       "56  0.036976      0.987812    0.022138        0.995000    0.096676   \n",
       "57  0.034681      0.988750    0.021839        0.993750    0.099407   \n",
       "58  0.040629      0.986563    0.021620        0.994687    0.100675   \n",
       "59  0.035330      0.989062    0.020808        0.994687    0.101289   \n",
       "\n",
       "    valid_accuracy  \n",
       "0          0.50125  \n",
       "1          0.74500  \n",
       "2          0.79875  \n",
       "3          0.85500  \n",
       "4          0.86250  \n",
       "5          0.90000  \n",
       "6          0.92625  \n",
       "7          0.92125  \n",
       "8          0.94750  \n",
       "9          0.94125  \n",
       "10         0.94750  \n",
       "11         0.92375  \n",
       "12         0.94125  \n",
       "13         0.95000  \n",
       "14         0.95500  \n",
       "15         0.94875  \n",
       "16         0.96125  \n",
       "17         0.96375  \n",
       "18         0.97000  \n",
       "19         0.95250  \n",
       "20         0.96000  \n",
       "21         0.96125  \n",
       "22         0.94750  \n",
       "23         0.95625  \n",
       "24         0.94875  \n",
       "25         0.95375  \n",
       "26         0.95875  \n",
       "27         0.96125  \n",
       "28         0.96875  \n",
       "29         0.96750  \n",
       "30         0.95625  \n",
       "31         0.93750  \n",
       "32         0.94750  \n",
       "33         0.95500  \n",
       "34         0.96250  \n",
       "35         0.96625  \n",
       "36         0.96750  \n",
       "37         0.96000  \n",
       "38         0.96125  \n",
       "39         0.92625  \n",
       "40         0.93875  \n",
       "41         0.96000  \n",
       "42         0.95875  \n",
       "43         0.95500  \n",
       "44         0.96125  \n",
       "45         0.96250  \n",
       "46         0.97000  \n",
       "47         0.96375  \n",
       "48         0.96500  \n",
       "49         0.96625  \n",
       "50         0.96750  \n",
       "51         0.96875  \n",
       "52         0.97000  \n",
       "53         0.97000  \n",
       "54         0.96625  \n",
       "55         0.96500  \n",
       "56         0.96500  \n",
       "57         0.96250  \n",
       "58         0.96375  \n",
       "59         0.96500  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9865625"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2[\"train_accuracy\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040022454233737174"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2[\"train_loss\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04672166628116406"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3[\"train_loss\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98375"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3[\"train_accuracy\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95875"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3[\"valid_accuracy\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"model_version\": 1,\n",
    "    \"model_weights\": \"../output/models/v-1/fold-1/model.pt\",\n",
    "    \n",
    "    \"augmentation_version\": 1,\n",
    "    \n",
    "    \"device\": \"cuda\",\n",
    "    \"batch_size\": 4000,\n",
    "    \"n_jobs\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = pkl_load(Path(\"../output/crossval_split/crossval_dct.pkl\"))\n",
    "\n",
    "df = dct[1][\"valid\"]\n",
    "dataset = MyDataset(df, get_augmentation(cfg[\"augmentation_version\"])[\"valid\"])\n",
    "dataloader = DataLoader(dataset, batch_size=cfg[\"batch_size\"], shuffle=False, num_workers=cfg[\"n_jobs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(cfg[\"model_version\"], cfg[\"model_weights\"])\n",
    "model.to(cfg[\"device\"])\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    pred = np.array([])\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(cfg[\"device\"]), y.to(cfg[\"device\"])\n",
    "        p = model.forward(x)\n",
    "        p = torch.sigmoid(p)\n",
    "        p = p.to(\"cpu\").numpy()\n",
    "        pred = np.append(pred, p)\n",
    "df[\"pred_proba\"] = pred\n",
    "df[\"pred\"] = (df[\"pred_proba\"] > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def preview(df, ncols, size):\n",
    "    nrows = int(len(df) / ncols) + (len(df) % ncols > 0)\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols,\n",
    "                            figsize=(ncols*size, nrows*size))\n",
    "    fig.patch.set_facecolor('white')\n",
    "    for ax in axs.flatten():\n",
    "        ax.axis('off')\n",
    "    for ax, (_, row) in zip(axs.flatten(), df.iterrows()):\n",
    "        img = cv2.imread(str(row[\"cew_img\"]), cv2.IMREAD_GRAYSCALE)\n",
    "        ax.imshow(img, cmap=plt.get_cmap('gray'))\n",
    "        ax.set_title(f\"True-{row.label} | Pred-{round(row.pred_proba, 3)}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preview_df = df[(df[\"label\"] != df[\"pred\"]) & (df[\"label\"] == 1)]\n",
    "print(f\"Total images: {preview_df.shape[0]}\")\n",
    "preview(preview_df, 5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_df = df[(df[\"label\"] != df[\"pred\"]) & (df[\"label\"] == 0)]\n",
    "print(f\"Total images: {preview_df.shape[0]}\")\n",
    "preview(preview_df, 5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_df = df[\n",
    "    (df[\"pred\"] == 1) &\n",
    "    \n",
    "    (df[\"pred\"] == df[\"label\"]) &\n",
    "    (df[\"pred_proba\"] > 0.3) &\n",
    "    (df[\"pred_proba\"] < 0.7)\n",
    "]\n",
    "print(f\"Total images: {preview_df.shape[0]}\")\n",
    "preview(preview_df, 5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_df = df[\n",
    "    (df[\"pred\"] == 0) &\n",
    "    \n",
    "    (df[\"pred\"] == df[\"label\"]) &\n",
    "    (df[\"pred_proba\"] > 0.3) &\n",
    "    (df[\"pred_proba\"] < 0.7)\n",
    "]\n",
    "print(f\"Total images: {preview_df.shape[0]}\")\n",
    "preview(preview_df, 5, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
